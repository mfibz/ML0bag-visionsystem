{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML0bag Vision System - Training Notebook\n",
    "\n",
    "**Luxury Bag Defect Detection & Authentication using YOLOv11**\n",
    "\n",
    "This notebook runs the full training pipeline. You can use it in:\n",
    "- **Google Colab** (with GPU runtime or connected to your local RTX 5090)\n",
    "- **Jupyter** running locally on your machine\n",
    "\n",
    "---\n",
    "\n",
    "## Setup Options\n",
    "\n",
    "| Option | How | Best For |\n",
    "|--------|-----|----------|\n",
    "| **A) Colab + Local GPU** | Colab connects to Jupyter on your PC | Use your RTX 5090 with Colab's UI |\n",
    "| **B) Colab GPU** | Use Colab's free/paid GPU | No local GPU available |\n",
    "| **C) Local Jupyter** | Run Jupyter directly on your PC | Full local control |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Connect Colab to Your Local RTX 5090\n",
    "\n",
    "**Skip this cell if running locally or using Colab's GPU.**\n",
    "\n",
    "To use your RTX 5090 from Google Colab, you need to run a local Jupyter runtime:\n",
    "\n",
    "### On your PC (one-time setup):\n",
    "\n",
    "```bash\n",
    "# 1. Install Jupyter with Colab local runtime support\n",
    "pip install jupyter jupyter_http_over_ws\n",
    "jupyter serverextension enable --py jupyter_http_over_ws\n",
    "\n",
    "# 2. Start the local runtime (run this every time)\n",
    "jupyter notebook \\\n",
    "  --NotebookApp.allow_origin='https://colab.research.google.com' \\\n",
    "  --port=8888 \\\n",
    "  --NotebookApp.port_retries=0\n",
    "```\n",
    "\n",
    "### In Google Colab:\n",
    "1. Click the dropdown arrow next to **\"Connect\"** (top right)\n",
    "2. Select **\"Connect to a local runtime\"**\n",
    "3. Enter the URL shown in your terminal (e.g., `http://localhost:8888/?token=...`)\n",
    "4. Click **Connect**\n",
    "\n",
    "Now Colab runs on your RTX 5090!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Install Dependencies & Clone Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Clone the project repo (update URL to your repo)\n",
    "    !git clone https://github.com/YOUR_USERNAME/ML0bag-visionsystem.git\n",
    "    %cd ML0bag-visionsystem\n",
    "else:\n",
    "    # If running locally, make sure you're in the project root\n",
    "    import os\n",
    "    # Adjust this path to where your project lives\n",
    "    # os.chdir('/path/to/ML0bag-visionsystem')\n",
    "    print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q ultralytics>=8.3.0 \\\n",
    "    torch torchvision \\\n",
    "    opencv-python-headless \\\n",
    "    huggingface-hub datasets \\\n",
    "    roboflow \\\n",
    "    Pillow numpy pandas pyyaml \\\n",
    "    tqdm matplotlib seaborn \\\n",
    "    loguru click albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify GPU is available\nimport torch\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    props = torch.cuda.get_device_properties(0)\n    # total_memory works across all PyTorch versions (total_mem was removed in 2.x)\n    vram = getattr(props, 'total_memory', None) or getattr(props, 'total_mem', 0)\n    print(f\"VRAM: {vram / 1e9:.1f} GB\")\nelse:\n    print(\"WARNING: No GPU detected. Training will be very slow on CPU.\")\n    print(\"If using Colab: Runtime > Change runtime type > GPU\")\n    print(\"If local: Make sure NVIDIA drivers and CUDA are installed.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Add project root to Python path\nimport os\nimport sys\nfrom pathlib import Path\n\nPROJECT_ROOT = Path.cwd()\n\n# Handle nested clone: ML0bag-visionsystem/ML0bag-visionsystem/\n# Walk down into nested copies until we find the deepest one with src/\nwhile (PROJECT_ROOT / 'ML0bag-visionsystem' / 'src').exists():\n    PROJECT_ROOT = PROJECT_ROOT / 'ML0bag-visionsystem'\n\n# If src/ is not in current dir, check common locations\nif not (PROJECT_ROOT / 'src').exists():\n    for candidate in [\n        Path('/home/programming/ML0bag-visionsystem/ML0bag-visionsystem'),\n        Path('/home/programming/ML0bag-visionsystem'),\n        Path('/content/ML0bag-visionsystem'),\n        Path.home() / 'ML0bag-visionsystem',\n    ]:\n        if (candidate / 'src').exists():\n            PROJECT_ROOT = candidate\n            break\n\nos.chdir(PROJECT_ROOT)\nif str(PROJECT_ROOT) not in sys.path:\n    sys.path.insert(0, str(PROJECT_ROOT))\n\nprint(f\"Project root: {PROJECT_ROOT}\")\nassert (PROJECT_ROOT / 'src').exists(), f\"ERROR: src/ not found in {PROJECT_ROOT}\"\n\n# Verify imports work\nfrom src.config.settings import ensure_dirs, get_device, load_config\nfrom src.utils.logging import setup_logger\n\nensure_dirs()\nprint(f\"Device: {get_device()}\")\nprint(\"Setup complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Download Datasets\n",
    "\n",
    "You need API keys for some datasets:\n",
    "- **Roboflow**: Free account at roboflow.com > Settings > API Key\n",
    "- **HuggingFace**: Optional, for gated datasets > huggingface.co > Settings > Access Tokens\n",
    "- **Kaggle**: For leather defects > kaggle.com > Settings > API > Create Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your API keys here (or use Colab Secrets)\n",
    "# In Colab: click the key icon on the left sidebar to add secrets\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    try:\n",
    "        os.environ['ROBOFLOW_API_KEY'] = userdata.get('ROBOFLOW_API_KEY')\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Or set them directly (don't commit this!):\n",
    "# os.environ['ROBOFLOW_API_KEY'] = 'your_key_here'\n",
    "# os.environ['HF_TOKEN'] = 'your_token_here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Dataset 1: CVandDL Bag Logos (Roboflow) - Phase 1\n",
    "from src.data.download import download_from_roboflow\n",
    "from src.config.settings import DATA_DIR\n",
    "\n",
    "roboflow_key = os.environ.get('ROBOFLOW_API_KEY', '')\n",
    "if roboflow_key:\n",
    "    logo_dir = download_from_roboflow(\n",
    "        workspace='cvanddl',\n",
    "        project='detection-bag-logo',\n",
    "        version=1,\n",
    "        api_key=roboflow_key,\n",
    "        output_dir=DATA_DIR / 'raw' / 'roboflow_logos',\n",
    "        format='yolov8',\n",
    "    )\n",
    "    print(f\"Logos downloaded to: {logo_dir}\")\n",
    "else:\n",
    "    print(\"Set ROBOFLOW_API_KEY to download the logo dataset.\")\n",
    "    print(\"Get a free key at: https://app.roboflow.com/settings/api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download Dataset 2: LFFD (HuggingFace) - Phase 3 Authentication\n# Uses huggingface_hub directly (the datasets library has compatibility issues with this dataset)\nfrom huggingface_hub import snapshot_download\nfrom pathlib import Path\n\nlffd_dir = Path('data/raw/lffd')\nlffd_dir.mkdir(parents=True, exist_ok=True)\n\nif not any(lffd_dir.rglob('*.jpg')) and not any(lffd_dir.rglob('*.parquet')):\n    print(\"Downloading LFFD dataset (2 GB, may take a few minutes)...\")\n    snapshot_download(\n        repo_id='Innovatiana/innv-luxury-fashion-dataset-fraud-detection',\n        repo_type='dataset',\n        local_dir=str(lffd_dir),\n        token=os.environ.get('HF_TOKEN'),\n    )\n    print(f\"LFFD downloaded to: {lffd_dir}\")\nelse:\n    print(f\"LFFD already downloaded at: {lffd_dir}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download Dataset 3: Leather Defects (Kaggle) - Phase 2 supplement\nimport os\nfrom pathlib import Path\n\nos.environ['KAGGLE_USERNAME'] = 'marcosiced'\nos.environ['KAGGLE_KEY'] = '5ecd78ca00c5ed99f788f36523beb29f'\n\nleather_dir = Path('data/raw/leather_defects')\n\nif leather_dir.exists() and any(d.is_dir() for d in leather_dir.iterdir()):\n    print(f\"Leather defects already at: {leather_dir}\")\n    for item in sorted(leather_dir.iterdir()):\n        if item.is_dir():\n            count = len(list(item.rglob('*.*')))\n            print(f\"  {item.name}/  ({count} files)\")\nelse:\n    !pip install -q kaggle\n    leather_dir.mkdir(parents=True, exist_ok=True)\n    !kaggle datasets download -d praveen2084/leather-defect-classification -p data/raw/leather_defects --unzip\n    print(f\"\\nDownloaded to: {leather_dir}\")\n    for item in sorted(leather_dir.iterdir()):\n        if item.is_dir():\n            count = len(list(item.rglob('*.*')))\n            print(f\"  {item.name}/  ({count} files)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Preprocess Datasets into YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport zipfile\nfrom pathlib import Path\nfrom src.config.settings import DATA_DIR\n\n# --- Extract LFFD zip if needed ---\nlffd_zip = DATA_DIR / 'raw' / 'lffd' / 'dataset-chanel-luxury-bags.zip'\nlffd_dir = DATA_DIR / 'raw' / 'lffd'\n\nif lffd_zip.exists():\n    # Count images already extracted\n    existing_imgs = list(lffd_dir.rglob('*.jpg')) + list(lffd_dir.rglob('*.jpeg')) + list(lffd_dir.rglob('*.png'))\n    # Only extract if we don't have many images yet (zip + readme = not extracted)\n    if len(existing_imgs) < 100:\n        print(\"Extracting LFFD zip (this may take a minute)...\")\n        with zipfile.ZipFile(lffd_zip, 'r') as zf:\n            zf.extractall(lffd_dir)\n        existing_imgs = list(lffd_dir.rglob('*.jpg')) + list(lffd_dir.rglob('*.jpeg')) + list(lffd_dir.rglob('*.png'))\n        print(f\"Extracted {len(existing_imgs)} images\")\n    else:\n        print(f\"LFFD already extracted: {len(existing_imgs)} images\")\n\n# --- Check Roboflow structure ---\nrf_dir = DATA_DIR / 'raw' / 'roboflow_logos'\nprint(\"\\n=== Roboflow Logos ===\")\nfor split in ['train', 'valid', 'test']:\n    img_dir = rf_dir / split / 'images'\n    if img_dir.exists():\n        count = len(list(img_dir.iterdir()))\n        print(f\"  {split}: {count} images\")\n    elif (rf_dir / split).exists():\n        # Images might be directly in the split folder\n        imgs = [f for f in (rf_dir / split).iterdir() if f.suffix.lower() in {'.jpg', '.jpeg', '.png'}]\n        print(f\"  {split}: {len(imgs)} images (flat structure)\")\n\n# --- Now preprocess all phases with force ---\nprint(\"\\n\" + \"=\" * 50)\nprint(\"Preparing Phase 1: Logo Detection\")\nprint(\"=\" * 50)\nfrom src.data.preprocess import prepare_phase1, prepare_phase2, prepare_phase3\n\nphase1_yaml = prepare_phase1(force=True)\nprint(f\"Phase 1 data config: {phase1_yaml}\\n\")\n\nprint(\"=\" * 50)\nprint(\"Preparing Phase 2: Condition Assessment\")\nprint(\"=\" * 50)\nphase2_yaml = prepare_phase2(force=True)\nprint(f\"Phase 2 data config: {phase2_yaml}\\n\")\n\nprint(\"=\" * 50)\nprint(\"Preparing Phase 3: Authentication\")\nprint(\"=\" * 50)\nphase3_dir = prepare_phase3(force=True)\nprint(f\"Phase 3 data dir: {phase3_dir}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset sizes\n",
    "from pathlib import Path\n",
    "from src.config.settings import DATA_DIR\n",
    "\n",
    "for phase in ['phase1', 'phase2', 'phase3']:\n",
    "    phase_dir = DATA_DIR / 'processed' / phase\n",
    "    print(f\"\\n--- {phase} ---\")\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        img_dir = phase_dir / 'images' / split\n",
    "        if img_dir.exists():\n",
    "            count = len(list(img_dir.iterdir()))\n",
    "            print(f\"  {split}: {count} images\")\n",
    "        else:\n",
    "            # Check classification format (phase3)\n",
    "            cls_dir = phase_dir / split\n",
    "            if cls_dir.exists():\n",
    "                for cls in cls_dir.iterdir():\n",
    "                    if cls.is_dir():\n",
    "                        count = len(list(cls.iterdir()))\n",
    "                        print(f\"  {split}/{cls.name}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Train Phase 1 - Bag & Logo Detection\n",
    "\n",
    "Detects bags in the image and identifies the brand logo.\n",
    "\n",
    "**Model**: YOLOv11m (medium) | **Expected time**: ~1-2 hours on RTX 5090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from src.config.settings import load_config, get_device, MODELS_DIR, RUNS_DIR\n",
    "import shutil\n",
    "\n",
    "# Load phase 1 config\n",
    "config = load_config('phase1_detection')\n",
    "device = get_device()\n",
    "print(f\"Training on: {device}\")\n",
    "\n",
    "# Load pretrained YOLOv11 medium\n",
    "model = YOLO(config['model']['architecture'])\n",
    "\n",
    "# Resolve data path\n",
    "data_path = str(PROJECT_ROOT / config['data']['config'])\n",
    "print(f\"Data config: {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train Phase 1\n# workers=0 and pin_memory=False prevent CUDA pin memory errors\n# when running through Colab local runtime\nresults = model.train(\n    data=data_path,\n    epochs=config['training']['epochs'],\n    imgsz=config['data']['imgsz'],\n    batch=config['training']['batch'],\n    device=device,\n    project=str(PROJECT_ROOT / config['output']['project']),\n    name=config['output']['name'],\n    patience=config['training']['patience'],\n    optimizer=config['training']['optimizer'],\n    lr0=config['training']['lr0'],\n    cos_lr=config['training']['cos_lr'],\n    save_period=config['output']['save_period'],\n    plots=True,\n    verbose=True,\n    workers=0,\n    **config.get('augmentation', {}),\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best weights\n",
    "best_src = Path(results.save_dir) / 'weights' / 'best.pt'\n",
    "best_dst = MODELS_DIR / 'phase1' / 'best.pt'\n",
    "best_dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if best_src.exists():\n",
    "    shutil.copy2(best_src, best_dst)\n",
    "    print(f\"Phase 1 best model saved to: {best_dst}\")\n",
    "\n",
    "# Show training results\n",
    "from IPython.display import Image, display\n",
    "results_img = Path(results.save_dir) / 'results.png'\n",
    "if results_img.exists():\n",
    "    display(Image(filename=str(results_img), width=900))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Train Phase 2 - Condition / Defect Detection\n",
    "\n",
    "Detects defects: scratches, tears, stains, wear, deformation.\n",
    "\n",
    "**Model**: YOLOv11m | **Expected time**: ~2-4 hours on RTX 5090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load phase 2 config\nconfig2 = load_config('phase2_condition')\n\nmodel2 = YOLO(config2['model']['architecture'])\ndata_path2 = str(PROJECT_ROOT / config2['data']['config'])\n\nresults2 = model2.train(\n    data=data_path2,\n    epochs=config2['training']['epochs'],\n    imgsz=config2['data']['imgsz'],\n    batch=config2['training']['batch'],\n    device=device,\n    project=str(PROJECT_ROOT / config2['output']['project']),\n    name=config2['output']['name'],\n    patience=config2['training']['patience'],\n    optimizer=config2['training']['optimizer'],\n    lr0=config2['training']['lr0'],\n    cos_lr=config2['training']['cos_lr'],\n    save_period=config2['output']['save_period'],\n    plots=True,\n    verbose=True,\n    workers=0,\n    **config2.get('augmentation', {}),\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Phase 2 best weights\n",
    "best_src2 = Path(results2.save_dir) / 'weights' / 'best.pt'\n",
    "best_dst2 = MODELS_DIR / 'phase2' / 'best.pt'\n",
    "best_dst2.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if best_src2.exists():\n",
    "    shutil.copy2(best_src2, best_dst2)\n",
    "    print(f\"Phase 2 best model saved to: {best_dst2}\")\n",
    "\n",
    "results_img2 = Path(results2.save_dir) / 'results.png'\n",
    "if results_img2.exists():\n",
    "    display(Image(filename=str(results_img2), width=900))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Train Phase 3 - Authentication (Real vs Fake)\n",
    "\n",
    "Classifies bags as authentic or counterfeit.\n",
    "\n",
    "**Model**: YOLOv11s-cls (classification) | **Expected time**: ~30-60 min on RTX 5090\n",
    "\n",
    "**IMPORTANT**: Phase 3 requires manually curated data. The LFFD dataset images are\n",
    "initially all placed in the `authentic` folder. You must:\n",
    "1. Review images and move counterfeit ones to `data/processed/phase3/train/counterfeit/`\n",
    "2. Also populate `data/processed/phase3/val/counterfeit/`\n",
    "3. Aim for at least 500+ images per class for reasonable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Phase 3 data readiness\n",
    "phase3_train = DATA_DIR / 'processed' / 'phase3' / 'train'\n",
    "phase3_val = DATA_DIR / 'processed' / 'phase3' / 'val'\n",
    "\n",
    "auth_count = len(list((phase3_train / 'authentic').glob('*'))) if (phase3_train / 'authentic').exists() else 0\n",
    "fake_count = len(list((phase3_train / 'counterfeit').glob('*'))) if (phase3_train / 'counterfeit').exists() else 0\n",
    "\n",
    "print(f\"Phase 3 training data:\")\n",
    "print(f\"  Authentic: {auth_count} images\")\n",
    "print(f\"  Counterfeit: {fake_count} images\")\n",
    "\n",
    "if fake_count < 100:\n",
    "    print(f\"\\nWARNING: Not enough counterfeit samples ({fake_count}).\")\n",
    "    print(\"You need to manually sort counterfeit images before training Phase 3.\")\n",
    "    print(f\"Place them in: {phase3_train / 'counterfeit'}/\")\n",
    "    PHASE3_READY = False\n",
    "else:\n",
    "    PHASE3_READY = True\n",
    "    print(\"\\nPhase 3 data looks ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train Phase 3 (only if data is ready)\nif PHASE3_READY:\n    config3 = load_config('phase3_authentication')\n    \n    model3 = YOLO(config3['model']['architecture'])\n    data_path3 = str(PROJECT_ROOT / config3['data']['config'])\n    \n    results3 = model3.train(\n        data=data_path3,\n        epochs=config3['training']['epochs'],\n        imgsz=config3['data']['imgsz'],\n        batch=config3['training']['batch'],\n        device=device,\n        project=str(PROJECT_ROOT / config3['output']['project']),\n        name=config3['output']['name'],\n        patience=config3['training']['patience'],\n        optimizer=config3['training']['optimizer'],\n        lr0=config3['training']['lr0'],\n        cos_lr=config3['training']['cos_lr'],\n        save_period=config3['output']['save_period'],\n        plots=True,\n        verbose=True,\n        workers=0,\n        **config3.get('augmentation', {}),\n    )\n    \n    # Save weights\n    best_src3 = Path(results3.save_dir) / 'weights' / 'best.pt'\n    best_dst3 = MODELS_DIR / 'phase3' / 'best.pt'\n    best_dst3.parent.mkdir(parents=True, exist_ok=True)\n    if best_src3.exists():\n        shutil.copy2(best_src3, best_dst3)\n        print(f\"Phase 3 best model saved to: {best_dst3}\")\nelse:\n    print(\"Skipping Phase 3 training - not enough counterfeit samples.\")\n    print(\"Complete the annotation step above first.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Test the Full Cascade Pipeline\n",
    "\n",
    "Run all 3 models in sequence: Detect bag -> Check condition -> Authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a single image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from src.inference.pipeline import CascadePipeline\n",
    "\n",
    "# Initialize the cascade pipeline (loads all available trained models)\n",
    "pipeline = CascadePipeline()\n",
    "\n",
    "# Load a test image - replace with your own image path\n",
    "test_image_path = 'path/to/your/test/bag/image.jpg'  # <-- CHANGE THIS\n",
    "\n",
    "if Path(test_image_path).exists():\n",
    "    image = cv2.imread(test_image_path)\n",
    "    \n",
    "    # Run full pipeline\n",
    "    results = pipeline.process(image)\n",
    "    \n",
    "    # Print results\n",
    "    for i, r in enumerate(results):\n",
    "        print(f\"\\nBag #{i+1}:\")\n",
    "        print(f\"  Brand/Type: {r.bag_type} ({r.detection_conf:.1%})\")\n",
    "        if r.condition:\n",
    "            print(f\"  Condition: {r.condition} ({r.condition_conf:.1%})\")\n",
    "        if r.auth_result:\n",
    "            print(f\"  Authentication: {r.auth_result} ({r.auth_conf:.1%})\")\n",
    "    \n",
    "    # Show annotated image\n",
    "    annotated = pipeline.annotate(image, results)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title('Cascade Pipeline Results')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Test image not found: {test_image_path}\")\n",
    "    print(\"Upload a bag image and update the path above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test: upload an image in Colab\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    print(\"Upload a bag image to test:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    for filename in uploaded:\n",
    "        image = cv2.imread(filename)\n",
    "        results = pipeline.process(image)\n",
    "        \n",
    "        for i, r in enumerate(results):\n",
    "            print(f\"\\nBag #{i+1}: {r.bag_type} ({r.detection_conf:.1%})\")\n",
    "            if r.condition:\n",
    "                print(f\"  Condition: {r.condition} ({r.condition_conf:.1%})\")\n",
    "            if r.auth_result:\n",
    "                print(f\"  Auth: {r.auth_result} ({r.auth_conf:.1%})\")\n",
    "        \n",
    "        annotated = pipeline.annotate(image, results)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Export Models for Production\n",
    "\n",
    "Export to ONNX for faster inference or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export trained models to ONNX format\n",
    "for phase in ['phase1', 'phase2', 'phase3']:\n",
    "    model_path = MODELS_DIR / phase / 'best.pt'\n",
    "    if model_path.exists():\n",
    "        print(f\"Exporting {phase}...\")\n",
    "        m = YOLO(str(model_path))\n",
    "        m.export(format='onnx')\n",
    "        print(f\"  Exported to: {MODELS_DIR / phase / 'best.onnx'}\")\n",
    "    else:\n",
    "        print(f\"  {phase}: No trained model found, skipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Download Trained Models (Colab only)\n",
    "\n",
    "If training in Colab, download your models to keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    import shutil\n",
    "    # Zip all models\n",
    "    shutil.make_archive('trained_models', 'zip', str(MODELS_DIR))\n",
    "    files.download('trained_models.zip')\n",
    "    print(\"Models downloaded!\")\n",
    "else:\n",
    "    print(f\"Models are saved at: {MODELS_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}